{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXY6WPEO91uD",
        "outputId": "9f80804e-861d-44ec-9989-e1f4a7a74254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output # For cleaner output during optimization\n",
        "\n",
        "# Device configuration (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition and Training (Quick MNIST)\n",
        "\n",
        "# Define the simple CNN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) # Layer to interpret (conv1)\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) # Layer to interpret (conv2)\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# MNIST Data Loaders\n",
        "# We only need the training loader to train the model quickly\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])),\n",
        "    batch_size=64, shuffle=True)\n",
        "\n",
        "# Initialize the model\n",
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01) # Use Adam for faster convergence\n",
        "epochs = 3 # A few epochs is enough for demonstration\n",
        "\n",
        "# Function to train the model\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() # Set model to training mode\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "print(\"Starting quick model training for interpretability demo...\")\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "\n",
        "# Crucial: Set the model to evaluation mode after training, and freeze its parameters\n",
        "# We don't want the model's weights to change during visualization\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"\\nModel training complete and frozen for interpretation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuQJS8py-8ln",
        "outputId": "c43c28c3-c947-45e9-a0dd-a8b5270cd682"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 479kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.44MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting quick model training for interpretability demo...\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.301575\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.888748\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.422770\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.410639\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.211572\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.156962\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.225517\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.228848\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.399617\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.870866\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.391358\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.165578\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.249694\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.711615\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.413608\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.192085\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.211915\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.227712\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.536449\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.255599\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.342825\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.600238\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.387995\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.263028\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.294073\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.184326\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.229273\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.218581\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.199329\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.255511\n",
            "\n",
            "Model training complete and frozen for interpretation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Visualization Core Logic (FINAL CORRECTED VERSION)\n",
        "\n",
        "# --- Configuration for Visualization (keeping same target) ---\n",
        "target_layer = model.conv1\n",
        "target_channel = 5\n",
        "target_neuron_xy = (2, 2)\n",
        "\n",
        "# --- Hook Setup (same as final successful version) ---\n",
        "activations_store = []\n",
        "def hook_fn(module, input, output):\n",
        "    activations_store.clear()\n",
        "    activations_store.append(output)\n",
        "hook = target_layer.register_forward_hook(hook_fn)\n",
        "\n",
        "# --- Input Image Initialization (CRITICAL FIX 1: Start from Gray) ---\n",
        "# Start with a uniform gray image (0.5 value) for cleaner feature generation\n",
        "input_img = torch.full((1, 1, 28, 28), 0.5, requires_grad=True, device=device)\n",
        "\n",
        "# --- Optimization Parameters (CRITICAL FIX 2: Reduce Learning Rate) ---\n",
        "# Reduce learning rate significantly to avoid overshooting and getting stuck\n",
        "viz_optimizer = optim.Adam([input_img], lr=0.005)\n",
        "num_iterations = 400 # Increase iterations for finer detail\n",
        "# ---\n",
        "\n",
        "print(f\"Visualizing neuron in {target_layer.__class__.__name__}, channel {target_channel}, location {target_neuron_xy}...\")\n",
        "\n",
        "# --- Optimization Loop ---\n",
        "for i in range(num_iterations):\n",
        "    viz_optimizer.zero_grad()\n",
        "    model(input_img)\n",
        "\n",
        "    # Access the captured activation tensor\n",
        "    activations = activations_store[0]\n",
        "    neuron_activation = activations[0, target_channel, target_neuron_xy[0], target_neuron_xy[1]]\n",
        "\n",
        "    # Maximize the activation\n",
        "    (-neuron_activation).backward()\n",
        "\n",
        "    # Update the input image\n",
        "    viz_optimizer.step()\n",
        "\n",
        "    # --- Post-processing ---\n",
        "    # Clip pixel values to a valid range (0-1 for images)\n",
        "    input_img.data.clamp_(0, 1)\n",
        "\n",
        "    if (i+1) % 50 == 0:\n",
        "        print(f\"Iteration {i+1}/{num_iterations}, Activation: {neuron_activation.item():.4f}\")\n",
        "\n",
        "hook.remove()\n",
        "print(\"\\nFeature visualization optimization complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pPk7KNN_KIP",
        "outputId": "bcdb063b-f516-408c-c5e4-3f7f46756b2b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizing neuron in Conv2d, channel 5, location (2, 2)...\n",
            "Iteration 50/400, Activation: 0.0145\n",
            "Iteration 100/400, Activation: 1.5175\n",
            "Iteration 150/400, Activation: 1.5476\n",
            "Iteration 200/400, Activation: 1.5476\n",
            "Iteration 250/400, Activation: 1.5476\n",
            "Iteration 300/400, Activation: 1.5476\n",
            "Iteration 350/400, Activation: 1.5476\n",
            "Iteration 400/400, Activation: 1.5476\n",
            "\n",
            "Feature visualization optimization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Feature\n",
        "\n",
        "# Move the optimized image to CPU and convert to numpy for plotting\n",
        "visualized_feature = input_img.squeeze().detach().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.imshow(visualized_feature, cmap='gray')\n",
        "plt.title(f\"Visualized Feature for Neuron in Layer {target_layer.__class__.__name__}, Channel {target_channel}\")\n",
        "plt.axis('off') # Hide axes for cleaner image\n",
        "plt.show()\n",
        "\n",
        "print(\"Successfully generated and visualized the feature.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Zq6Fyu0cACLI",
        "outputId": "19ebb970-c97a-4051-e30e-9bfe986d4289"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully generated and visualized the feature.\n"
          ]
        }
      ]
    }
  ]
}